{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of image_processing_practice_with_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coyens/Python/blob/master/warsztaty/image_processing%20in%20keras/image_processing_clothes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TLKdxv4fwDx",
        "colab_type": "code",
        "outputId": "31f0a030-0867-41ca-bc00-2ba9e775d78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "import os\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNQZtbspNrMF",
        "colab_type": "text"
      },
      "source": [
        "# Gather the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhG7_A0PglI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load CIFAR 10 images\n",
        "# description of this dataset can be seen here:\n",
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoQlVlpbhfVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# both X and y are numpy arrays\n",
        "# the most essential infomation about numpy arrays is in their shape\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkWgb31vihuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign seventh example from training batch to variable called \"example_img\"\n",
        "example_img = deepcopy(X_train[7])\n",
        "print('Label number for that class:', y_train[7])\n",
        "# display img\n",
        "plt.imshow(example_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLiuG7VILVgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the shape of example_img\n",
        "example_img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_WlqpncejXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract first channel from example_img and assign it to 'red_channel' variable\n",
        "# red_channel var shape should be (32, 32)\n",
        "##TODO\n",
        "red_channel = \n",
        "##TODO\n",
        "assert red_channel.shape == (32, 32)\n",
        "plt.imshow(np.concatenate([red_channel[..., None], \n",
        "                           np.zeros(shape=(32, 32, 2), dtype='int')], axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P45daHD9swLt",
        "colab_type": "text"
      },
      "source": [
        "# Image classifier (dense neural network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlqSst6Kpqa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IH8AleDqLQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a dense neural architecture that receives input vector of length 3072\n",
        "# and outputs prediction for 10 classes (softmax activation)\n",
        "# use Adam optimizer, categorical_crossentropy loss\n",
        "# our metrics will be accuracy\n",
        "\n",
        "dense_network = Sequential()\n",
        "##TODO build your dense network !\n",
        "\n",
        "dense_network.compile(##TODO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79oSBedNORWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_network.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb7iiZW7sHPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##TODO\n",
        "# flatten the X_train examples ((50000, 32, 32, 3) -> (50000, 3072))\n",
        "# hint: you can use numpy reshape function\n",
        "X_train_flat = \n",
        "assert X_train_flat.shape == (50000, 3072)\n",
        "\n",
        "##TODO\n",
        "# convert the X_train_flat array value range from (0; 255) to (0; 1)\n",
        "X_train_flat = \n",
        "assert np.max(X_train_flat) <= 1.\n",
        "\n",
        "##TODO\n",
        "# convert y_train to one hot encoding\n",
        "# hint: you can use keras.utils.to_categorical function\n",
        "y = \n",
        "assert y.shape == (50000, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZwwHU31thoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##TODO\n",
        "# train your network\n",
        "# use batch size 32, split the dataset into train/validation (0.7/0.3)\n",
        "# keep training for 10 epochs\n",
        "dense_network.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qvdOMrU6Fcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_random_prediction(x, y, model):\n",
        "  pool = len(x)\n",
        "  random_int = np.random.randint(low=0, high=pool)\n",
        "  if len(model.input.shape) == 2:\n",
        "    sample = x[random_int].reshape(1, -1)\n",
        "  else:\n",
        "    sample = x[random_int][None, ...]\n",
        "  prediction = model.predict(sample)\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(x[random_int])\n",
        "  print('Predicted label:', np.argmax(prediction))\n",
        "  print('Actual label:', y[random_int][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36MMTlXT6Ogy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rerun this cell to show random predictions\n",
        "show_random_prediction(X_train, y_train, dense_network)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgfpKfyO2RaL",
        "colab_type": "text"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ooQWLWFLcIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write a fuction that converts RGB images (32, 32, 3) to grayscale (32, 32, 1)\n",
        "# you can just take an average of all channels (easy way)\n",
        "# the more elegant method is to extract weighted average (luminosity method)\n",
        "# the weights are: 0.29 R + 0.58 G + 0.11 B\n",
        "def rgb2gray(img):\n",
        "  ##TODO\n",
        "  return ##TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IMIjelpMSI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_img_gray = rgb2gray(example_img)\n",
        "plt.imshow(example_img_gray, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO5rzGPhi8ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will create convolutional filter using keras.layers.Conv2D class\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "conv_filter = Sequential()\n",
        "##TODO\n",
        "# add one convolutional layer that will be a single filter of kernel size = 3\n",
        "# use 'valid' padding and set the name parameter as 'convolution'\n",
        "# remember to set input_shape (but now it will be 3-dimensional)\n",
        "conv_filter.add(Conv2D())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhKq7wUuY385",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape example_img_gray to include also batch size\n",
        "example_img_gray = example_img_gray.reshape(1, 32, 32, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAc2rq_VSpA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display how conv_filter changes image\n",
        "result = conv_filter.predict(example_img_gray).reshape(30, 30)\n",
        "plt.imshow(result, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54WNMsaacDSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print conv_filter weights\n",
        "conv_filter.get_layer(name='convolution').get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JqHX1QLdsy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's define custom kernel! \n",
        "# Some of useful kernel patterns are presented here: \n",
        "# https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
        "# ofc you can define your own values\n",
        "# for the example, I'll use edge detection kernel\n",
        "kernel = np.array([\n",
        "                   [0, 1, 0], \n",
        "                   [1, -4, 1],\n",
        "                   [0, 1, 0]\n",
        "])\n",
        "\n",
        "# as you can see above, extracted parameters from Conv2D layer are a list\n",
        "# The list has two elements:\n",
        "\n",
        "# first one is actual convolutional kernel of shape (k, k, n, m)\n",
        "# where k is a kernel size\n",
        "# n is number of channels in previous layer\n",
        "# m is number of channels in actual layer\n",
        "\n",
        "# the second element of Conv2D parameters list is just a bias parameter\n",
        "# we will set it to 0. for the experiment\n",
        "kernel = [kernel.reshape(3, 3, 1, 1), np.array([0.])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y8dxTS2U-f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filter.get_layer(name='convolution').set_weights(kernel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Cwn9iDVfYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filter.get_layer(name='convolution').get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1M93XkKV3Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display image processed by your custom filter\n",
        "result = conv_filter.predict(example_img_gray).reshape(30, 30)\n",
        "plt.imshow(result, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOdlwJxwFm3a",
        "colab_type": "text"
      },
      "source": [
        "# LeNet\n",
        "![alt text](https://miro.medium.com/max/1700/1*AwJZkWLKabIicUPzSN6KCg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdE7r6bcFgAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.pooling import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "# build your LeNet model !\n",
        "\n",
        "LeNet = Sequential()\n",
        "##TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQW9H0wUKQMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print summary of your ConvNet\n",
        "LeNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wacO2HaMOED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile your model, using:\n",
        "# 1. Categorical crossentropy loss\n",
        "# 2. Accuracy metric\n",
        "# 3. Any optimizer you want (in most cases Adam provides good performance)\n",
        "LeNet.compile()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlqIafvPOIIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now use X_train as feature data (since it is not flattened)\n",
        "# do not flatten, keep 4 dimensions (#examples, width, height, #channels)\n",
        "# the only thing to do is to reduce the value range from (0; 255) to (0; 1)\n",
        "# last time we did the normalization for 'X_train_flat', not 'X_train'\n",
        "X_train = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHKOy2__Ojb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you still have 'y' variable saved as one hot encoded labels, keep going\n",
        "# otherwise just run this cell\n",
        "y = keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHCaG2bSN3eX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now train your LeNet with the X_train and y\n",
        "# leave the rest of parameters the same (as for Dense), so you can compare\n",
        "# which network learns better\n",
        "LeNet.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMWBDpyTSr2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rerun this cell to show random predictions\n",
        "show_random_prediction(X_train, y_train, LeNet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LZko2G3UzvP",
        "colab_type": "text"
      },
      "source": [
        "# Inception\n",
        "![alt text](https://miro.medium.com/max/1920/1*gqKM5V-uo2sMFFPDS84yJw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOU-qO6CS4v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from matplotlib.image import imread\n",
        "from cv2 import resize, flip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoWs5adLddRh",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TSJkKvreAHd",
        "colab_type": "text"
      },
      "source": [
        "For higher-resolution images example I've prepared dataset from Kaggle: https://www.kaggle.com/slothkong/10-monkey-species.\n",
        "The dataset contains ~1.5k images of 10 monkey species. Code below preprocess this images to feed and fine-tune Inception for monkey classification task.\n",
        "\n",
        "Ofc you can use your own idea for fine-tuning task. Feel free to improvise, otherwise you can play with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j26qg9pRpC0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/Drpulti/monkey_images.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2YDwN-wdZJLd",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "monkey_labels = pd.read_csv('monkey_images/monkey_labels.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW0xWHd7LGJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this DataFrame needs some preprocessing because it's messy\n",
        "monkey_labels.iloc[:, 0] = monkey_labels.iloc[:, 0].apply(lambda x: x.split()[0])\n",
        "monkey_labels.iloc[:, 2] = monkey_labels.iloc[:, 2].apply(lambda x: x.split()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipCWvm9FKuJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_dict = dict(zip(monkey_labels.iloc[:, 0], monkey_labels.iloc[:, 2]))\n",
        "labels_ids = dict(zip(monkey_labels.iloc[:, 0], range(len(monkey_labels))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RxNHjPekuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_and_resize(img, width, height):\n",
        "  w, h, c = img.shape\n",
        "  if w-h == 0:\n",
        "    return resize(img, (width, height))\n",
        "  if w > h:\n",
        "    diff = w-h\n",
        "    img = img[diff//2:-diff//2, :, :]\n",
        "  else:\n",
        "    diff = h-w\n",
        "    img = img[:, diff//2:-diff//2, :]\n",
        "  return resize(img, (width, height))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAkqc0yxdaEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target image resolution would be (299, 299). It's the inception's input size\n",
        "width = 299\n",
        "height = 299\n",
        "train_path = 'monkey_images/training/training/'\n",
        "\n",
        "# placeholders for image data and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for directory in os.listdir(train_path):\n",
        "  print(directory)\n",
        "  for img in os.listdir(train_path + directory):\n",
        "    img = imread(train_path + directory + '/' + img)\n",
        "    img = crop_and_resize(img, width, height)\n",
        "    images.append(img)\n",
        "    labels.append(labels_ids[directory])\n",
        "\n",
        "    # add also mirrored version of training image, to increase image pool size\n",
        "    images.append(flip(img, 1))\n",
        "    labels.append(labels_ids[directory])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJyBBspmTbQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load validation images, this time we won't augment the data\n",
        "# it would corrupt the results\n",
        "validation_path = 'monkey_images/validation/validation/'\n",
        "val_images = []\n",
        "val_labels = []\n",
        "\n",
        "for directory in os.listdir(validation_path):\n",
        "  print(directory)\n",
        "  for img in os.listdir(validation_path + directory):\n",
        "    img = imread(validation_path + directory + '/' + img)\n",
        "    img = crop_and_resize(img, width, height)\n",
        "    val_images.append(img)\n",
        "    val_labels.append(labels_ids[directory])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiSZFKayehkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels).reshape(-1, 1)\n",
        "\n",
        "val_images = np.array(val_images)\n",
        "val_labels = np.array(val_labels).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0lJatrkNztv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = images / 255.\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "val_images = val_images / 255.\n",
        "val_labels = to_categorical(val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc_5W29NPuon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "images, labels = shuffle(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ZZBErhQDjM",
        "colab_type": "text"
      },
      "source": [
        "# Inception fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCVAKLFFP_1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception = InceptionV3(include_top=False, \n",
        "                        weights='imagenet', \n",
        "                        input_shape=(299, 299, 3))\n",
        "\n",
        "# freeze most of the Inception layers, leave only the last ones as 'Trainable'\n",
        "for layer in inception.layers[:-5]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyKab2K0QWN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment if you want to print Inception layers\n",
        "# inception.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQjuu8dxQnM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_inception = Sequential()\n",
        "custom_inception.add(inception)\n",
        "custom_inception.add(Flatten())\n",
        "custom_inception.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ascrWbUFR3p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_inception.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHmUesyeQu_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_inception.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajisdIQIREa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_inception.fit(x=images, y=labels, batch_size=16, epochs=20, validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20f28Nk3SfqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}